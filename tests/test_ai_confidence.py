"""
Quick test to verify AI confidence scoring works (not binary veto)
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

print("=" * 70)
print("AI CONFIDENCE SCORING TEST")
print("=" * 70)

# Test that confidence values translate to size multipliers
test_cases = [
    (0.10, "Should be REJECTED (< 0.15 threshold)"),
    (0.20, "Should scale down position size"),
    (0.50, "Should scale moderately"),
    (0.85, "Should approve full size"),
    (0.95, "Should approve full size"),
]

print("\nExpected Behavior:")
print("-" * 70)
for confidence, expected in test_cases:
    if confidence < 0.15:
        result = "REJECT (don't execute)"
    elif confidence >= 0.80:
        result = "APPROVE (100% position)"
    else:
        # Rough estimate of size multiplier
        size_pct = int(confidence * 100)
        result = f"EXECUTE ({size_pct}% position)"

    print(f"Confidence {confidence:.2f}: {result:30s} | {expected}")

print("\n" + "=" * 70)
print("What Changed:")
print("=" * 70)
print("BEFORE (Binary Veto):")
print("  - if not filter_result.should_execute: continue")
print("  - Blocked 99.4% of signals (689/693)")
print()
print("AFTER (Confidence Scoring):")
print("  - if filter_result.confidence < 0.15: continue")
print("  - Blocks ~15% of signals (very low confidence only)")
print("  - Scales position size: 0.15-1.0 confidence â†’ 15%-100% size")
print("=" * 70)
